% 6. Post-Mortem 
\chapter{Evaluation}
\label{chap:evaluation}
This chapter attempts to identify and spell out the causes of the project failure. The project timeline will allow a quantitative overview of the project progression and show what parts of the project slowed down progress. Then, an overview of the qualitative aspects of the deliverables will discuss the maturity of the implementation and which parts reached a satisfactory level. %TODO: Restructure

\section{What Constitutes the Failure}
\emph{TBD: What failed? Why was the implementation not successful?}

\section{Quantitative Overview: Time Management}
\label{sec:pm-time-management}
Comparing the planned thesis schedule to the actual course it has taken, this section discusses how the intended plan was implemented and changed at certain places. Also, it will examine the causes of the delays during development.
\subsection{Project Timeline}
\label{sec:project-timeline}
Table \ref{fig:thesis-schedule} shows the initially planned thesis schedule divided into four phases, laying out the course of the thesis over a span of 24 weeks.

\begin{table}
    \centering
    \begin{tabular}{l l}
        \toprule
        Phase / Task             & Duration              \\
        \midrule
        1. Preparation           & $4$ weeks ($16,66\%$) \\
        \midrule
        Literature Research      & $1$ week              \\
        Expert Interviews        & $1$ week              \\
        Testbed Configuration    & $2$ weeks             \\
        \midrule
        2. Prototype             & $7$ weeks ($29,16\%$) \\
        \midrule
        Prototype Conception     & $2$ weeks             \\
        Prototype Implementation & $4$ weeks             \\
        Expert Feedback          & $1$ week              \\
        \midrule
        3. Functional Prototype  & $7$ weeks ($29,16\%$) \\
        \midrule
        FP Conception            & $2$ weeks             \\
        FP Implementation        & $4$ weeks             \\
        Expert Feedback          & $1$ week              \\
        \midrule
        4. Finalization          & $6$ weeks ($25\%$)    \\
        \midrule
        MQTT Case Study          & $2$ weeks             \\
        Thesis Finalization      & $4$ weeks             \\
        \midrule
        \midrule
        \emph{Total}             & \emph{$24$ weeks}     \\
        \bottomrule
    \end{tabular}
    \caption{Initially planned schedule for the thesis}
    \label{fig:thesis-schedule}
\end{table}

\paragraph{1. Preparation} The initial phase covered preparation tasks for further work on the thesis. Literature research on the topics covered and touched in this thesis was carried out. Related work on \ac{IoT} and \ac{ICS} security analysis (as discussed in chapter \ref{chap:related-work}) was of special interest as those showed what approaches had been taken to assess security implementations. Also, a testbed (discussed in section \ref{sec:prototype-testing}) for running the proxy application was built. A decision was made against conducting expert interviews before implementing a first prototype on the assumption that practical experience with the subject matter would benefit the expert interviews. The fact that a number of important questions arose from work on the first prototype later proved this decision to be correct. Performing the literature research and building a testbed was completed within the intended schedule of three weeks.
\paragraph{2. Prototype} In the second phase, the prototype discussed in section \ref{sec:prototypical-implementation} was designed and implemented in weekly sprints. Preceding these sprints, a rough design of the prototype's architecture and runtime behaviour was worked out in one week that would serve as a base for further design refinement and implementation in the sprints. These sprints ran for eight weeks in total: the initial design turned out to be too oversimplified so that sprints aiming to design and implement specific components were conducted rather isolated from other components that still needed to be worked on. As a result, both the integration of individual components and their interaction would fail and require redesigns and time-consuming adjustments to their implementation. Also, neither was the prototype mature enough to be used as a proxy application, nor was the resulting design and implementation clean enough to suggest putting further effort into working on them. After these eight sprints, work on this prototype was stopped and the expert interviews discussed in section \ref{sec:interviews} were prepared and conducted. It was found that the project was technically challenging and more complex than initially anticipated so the expert interviews were conducted to aid in re-engineering the design concept.

\paragraph{3. Functional Prototype} The third phase was intended to yield a design concept mature enough to both fulfil realistic requirements to a proxy application and be implemented. This was initiated by switching the technology stack from TypeScript to Python and re-designing and re-implementing large parts of the first prototype. In order to avoid the same mistake of refining a vague design concept and spending time adjusting the design and implementation to make them work, two weeks were spent on iterations of new design concepts discussed in chapter \ref{chap:conceptual-design}. These concepts did not only define single components but also interfaces that specified how those components interacted with each other, aiming for clear separation of components and high flexibility in implementation. Components of the prototype that were independent of the communication protocols used at runtime, such as NetStacks and \acp{FSM}, were implemented first over the span of four weeks. Then, implementations for supporting the \ac{HTTP}, \ac{WS} and \ac{MQTT} protocols followed over a span of another six weeks. Work on this prototype was stopped after those ten weeks as the technical difficulties discussed in section \ref{sec:pm-challenges} made estimations over the remaining time needed to finish the prototype both hard to make and rather unreliable.
\paragraph{4. Finalization} The final phase was intended to conduct a case study on how the proxy application would perform on scenario \# 2 from section \ref{sec:example-scenarios}. Tests were made to run the proxy application in the testbed shown in section \ref{sec:prototype-testing} which featured the same communication protocols that were used in scenario \# 2. However, the proxy application failed to reliably transmit or encode the messages sent between the \ac{MQTT} client and broker, thus resulting in a broken communication channel. The complex runtime behaviour and very time-consuming debugging of the proxy application (further elaborated on in section \ref{sec:pm-challenges}) lead to the decision to stop the project.

\begin{table}
    \centering
    \begin{tabular}{l l}
        \toprule
        Phase / Task             & Duration            \\
        \midrule
        1. Preparation           & $3$ weeks ($12\%$)  \\
        \midrule
        Literature Research      & 1 week              \\
        Testbed Configuration    & 2 weeks             \\
        \midrule
        2. TypeScript Prototype  & $10$ weeks ($40\%$) \\
        \midrule
        Prototype Conception     & 1 week              \\
        Prototype Implementation & 8 weeks             \\
        Expert Interviews        & 1 week              \\
        \midrule
        3. Python Candidate      & $12$ weeks ($48\%$) \\
        \midrule
        RC Conception            & 2 weeks             \\
        RC Implementation        & 10 weeks            \\
        \midrule
        \midrule
        \emph{Total}             & \emph{25 weeks}     \\
        \bottomrule
    \end{tabular}
    \caption{Actual schedule of the project}
    \label{fig:thesis-schedule-actual}
\end{table}

Table \ref{fig:thesis-schedule-actual} shows the actual schedule of the thesis. As can be seen, $88\%$ ($22$ weeks) of the time working on the thesis was spent designing and implementing the prototypes compared to a planned portion of roughly $60\%$ ($14$ weeks).

% Typescript prototype: March 2020
% Python prototype: November 2020 - December 2020

\subsection{Development Challenges}
\label{sec:pm-challenges}
There was a series of development challenges that slowed down implementation of both prototypes considerably:
\paragraph{Complex runtime behaviour} The combination of nested \acp{FSM} and pipelines lead to several problems during development. Even comparatively simple scenarios to use the proxy application in required a complete configuration file. This file was made of a global state machine and at least one network stack. This lead to a dynamic and long chain of references at runtime that made tracing back calls and attributing them to specific instances difficult.\\
Some problems such as a timing problem in the implementation of \acp{FSM} were very time consuming to debug: an \ac{FSM} would change its state when any of its rules was evaluated successfully and indicated a state change. By design, all \acp{FSM} of an active netstack would evaluate their rules when a message entered or left any netstack. When a higher-level \ac{FSM} (e.g. the global state-machine) changed its state \emph{while} a message was still being processed in a lower-level \ac{FSM}, the higher-level state-machine would change to another netstack, thus disconnect the lower-level state-machine. Eventually, the message would be processed back up and run into a pipe that had no upstream connection anymore, raising an exception and terminating the program. This particular error was discovered during the implementation and testing of the \ac{MQTT} encoder, in a runtime setup that involved a global default state-machine with a default \ac{TCP} netstack and a state-machine that handled \ac{HTTP} to \ac{WS} upgrades and processed \ac{MQTT} messages utilizing network stacks for \ac{HTTP} and \ac{WS}/\ac{MQTT}.\\
Other problems uncovered design flaws and required prompt changes to the software design or, in some cases, introduced new constraints to the project. One such example was discovered while testing the \ac{HTTP} encoder implementation using Mozilla FireFox as an \ac{HTTP} client. When browsing websites, the browser would open multiple connections to the target host to acquire multiple files at the same time\footnote{For testing single \ac{HTTP} connections, the key \emph{network.http.max-connections-per-server} could be set to $1$ in the \emph{about:config} page.}. This required the proxy application to instantiate a new pipeline per incoming connection rather than reside on using a single pipeline. However, the pipeline design dictated that pipes were connected to at most one preceding and one succeeding pipe. In order to connect pipelines to \acp{FSM}, the \acp{FSM} needed to provide a pipe-interface themselves. Thus, when instantiating multiple pipelines, these could not be connected to the global state-machine because the global state-machine's pipe-interface could only be connected to a single pipeline at a time. Therefore, a multiplexing pipe needed to be implemented to solve this issue. Alternatively, the proxy application could enforce instantiation of one single pipeline only to avoid changes to the software design. For a lab environment, enforcing the use of a single connection might work, however in real scenarios this constraint could potentially lead to the proxy application breaking applications at runtime.
To enable future implementations to support multiple connections, the software design was changed in a way that would allow the proxy to handle multiple connections. However, due to its academic nature, the prototype would only support a single connection at a time to reduce complexity.
\paragraph{Open source libraries} Both prototypes made use of open source libraries that implemented various protocols and included serialization and de-serialization routines for handling protocol specific packets. However, such libraries appeared to be intended to be used for developing applications that used those protocols as a means for transporting data rather than directly parsing packets.\\
Usually, these libraries would offer an API that allowed to instantiate and operate clients and servers and bind callbacks to events. The implementations of packet serialization and de-serialization were often times hidden through encapsulation, missing typings or poorly documented. For instance, the JavaScript library \enquote{ws}\footnote{https://github.com/websockets/ws, version 7.0.0, commit 092a822a41eb22f6d6745c18bc29b9c40715680f} provided methods for serialization and de-serialization but lacked typings
%\footnote{The version used for the TypeScript prototype was version 7.0.0, source code is available at https://github.com/websockets/ws.}
. Typings for this library were made available by the project \enquote{DefinitelyTyped}, however those did not include the classes relevant for serialization and de-serialization (\enquote{Sender} and \enquote{Receiver})\footnote{https://github.com/DefinitelyTyped/DefinitelyTyped/, commit 4bf23527293b2943c7fc12585c21473905a564d7}
%\footnote{As can be seen here: https://github.com/DefinitelyTyped/DefinitelyTyped/blob/4bf23527293b2943c7fc12585c21473905a564d7/types/ws/index.d.ts}
.
At the time of implementing the Python prototype, it used the library \enquote{websockets} that offered only an async de-serialization method
%\footnote{The python prototype used the library at commit 6b5cbaf41cdbc9a2074e357ccc613ef25517dd32: https://github.com/aaugustin/websockets/blob/6b5cbaf41cdbc9a2074e357ccc613ef25517dd32/src/websockets/framing.py}
(\enquote{framing.Frame.read}), requiring the use of asyncio which was circumvented by implementing a wrapper around it.\\
The Python prototype also used the \enquote{hbmqtt} library to (de-)serialize \ac{MQTT} messages. The library used an object-oriented implementation for (de-)serializing \ac{MQTT} messages where a class for each \ac{MQTT} message type (e.g. \emph{CONNECT}, \emph{CONNACK...}) inherited from an abstract \enquote{MQTTPacket} superclass %\footnote{https://github.com/beerfactory/hbmqtt/blob/31165fb0e827925417f99a7b1f475a9d67e1c72f/hbmqtt/mqtt/packet.py\#L186}
that defined a \enquote{to\_bytes} method for serialization and an async \enquote{from\_stream} method for de-serialization. Since the library did not implement a generic method that parsed a byte-buffer and returned the appropriate \ac{MQTT} message object, this logic had to be implemented as part of the work in the prototype, requiring investigation of the (largely uncommented) source code of the library as its documentation did not cover these internal (de-)serialization methods but focused on high-level use of the API it implemented.\\
From a software engineering point of view, omitting public interfaces to internal (de-)serialization methods and forcing specific programming patterns (such as async programming) are perfectly valid decisions in the context of single, individual modules. However, for those reasons, making use of the functionalities implemented in those libraries, was not trivial. It involved developing workarounds and investigating the libraries' source code which in turn took up time during the implementation phases.\\
Then there were also instances of incomplete documentation: the Python library \enquote{websockets} implemented (de-)serialization of \ac{WS} packets and also implemented the \ac{PMCE}%\footnote{Available at https://github.com/aaugustin/websockets/blob/6b5cbaf41cdbc9a2074e357ccc613ef25517dd32/src/websockets/extensions/permessage\_deflate.py}
of the \ac{WS} protocol. Calling the (de-)serialization methods of the \enquote{websockets} library and specifying the use of \ac{PMCE}, the first incoming and outgoing messages would be compressed correctly, however following messages would be compressed incorrectly. This rendered the prototype useless as \ac{WS} may use \ac{PMCE} by default to reduce bandwidth. The library failed to raise exceptions or return error codes so from the prototype's runtime point of view it appeared to work just fine. After investigating the library's source code it was found that the instances implementing the extension were stateful. When supplying newly created instances of said extension implementation to the (de-)serialization methods, they worked as intended, compressing and decompressing any amount of \ac{WS} packets. This could be due to a multitude of reasons including improper use of the \ac{PMCE} instances or improper calling of the (de-)serialization methods. No documentation could be found about specifics on those specific topics, though.\\
For Python libraries, one reason why documentation was in some cases sparse, only documented high-level features and largely omitted in-code documentation (such as comments) might be the \enquote{pythonic} approach to writing Python code. \enquote{Pythonic} code values readability higher than performance and encourages writing self-explanatory code%TODO: ref https://dl.acm.org/doi/abs/10.1145/3276954.3276960
. While this way of programming may help to understand individual methods or even algorithms that use multiple methods, it does not by itself aid in documentation of high-level concepts or complex interaction. Another reason for sparse documentation in open source libraries might be the developers' focus on implementing more features or improving the code-base instead of aiming for more complete documentation. Contrary to commercial products, there usually are no monetary incentives for developers of open source software to write documentation.

\section{Qualitative: Deliverables}
\label{sec:pm-deliverables}
\emph{TBD: Which fit-criteria were met? What is the implementation currently capable of? Which requirements were not full-filled?}